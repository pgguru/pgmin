#!/usr/bin/python3

from enum import Enum
from itertools import product
import fileinput
from random import shuffle

class State(Enum):
    START = 1
    IN_STRING = 2
    OTHER = 3
    NUMERIC = 4
    WORD = 5
    COMMENT = 6

def tokenize(input):
    """Turn the input string into a list of strings based on simple
    tokenization rules (basically quoted strings are a single
    token). there is implicit whitespace between all tokens.
"""
    state = State.START
    ret = ''
    qc = ''

    i = -1

    while i < len(input) - 1:
        i = i + 1
        c = input[i]
        if state in [State.START, State.NUMERIC, State.OTHER, State.WORD]:
            if c.isspace():
                if len(ret) > 0:
                    yield ret
                    ret = ''
                state = State.START
            elif c.isdigit() and state == State.START:
                if len(ret) > 0:
                    yield ret
                    ret = ''
                ret = '' + c
                state = State.NUMERIC
            elif state == State.NUMERIC and c in "0123456789.":
                ret = '' + c
            elif c.isalnum() or c in "_":
                if state in [State.START, State.WORD]:
                    state = State.WORD
                    ret = ret + c
                else:
                    if len(ret) > 0:
                        yield ret
                        ret = ''
                    ret = '' + c
                    state = State.WORD
            elif c == "-" and input[i+1] == "-":
                if len(ret) > 0:
                    yield ret
                    ret = ''
                state = State.COMMENT
                qc = "\n"
            elif c == "/" and input[i+1] == "*":
                if len(ret) > 0:
                    yield ret
                    ret = ''
                state = State.COMMENT
                qc = "*/"
            elif c in "\"'":
                if len(ret) > 0:
                    yield ret
                    ret = ''
                state = State.IN_STRING
                ret = ret + c
                qc = c
            else:
                # catchall
                if state == State.OTHER:
                    ret = ret + c
                else:
                    if len(ret) > 0:
                        yield ret
                        ret = ''
                    ret = '' + c
                    state = State.OTHER
        elif state == State.IN_STRING:
            ret = ret + c
            if c == qc:
                if len(ret) > 0:
                    yield ret
                    ret = ''
                state = State.START
        elif state == State.COMMENT:
            # we are discarding comments, so just ignore anything that isn't our closing sequence
            if qc == "\n" and c == "\n":
                state = State.START
            elif c == "*" and input[i+1] == '/':
                state = State.START
                i = i + 1
    if len(ret) > 0: yield ret

def idents():
    lists = []
    while True:
        chars = [chr(n) for n in range(ord('a'), ord('z') + 1)] + [chr(n) for n in range(ord('A'), ord('Z') + 1)]
        shuffle(chars)
        lists.append(chars)
        for c in product(*lists):
            yield ':' + (''.join(c))

ident = iter(idents())
xform = dict()

out = []
for line in fileinput.input():
    for t in tokenize(line):
        if len(t) > 2 and t[0].isalpha() or t[0] in "-_":
            #print(f'transforming {t}')
            # we are a transformable token
            key = xform.setdefault(t.lower(), next(ident))
            out.append(key)
        else:
            #print(f'ignoring {t}')
            out.append(t)
for k,v in sorted(xform.items()):
    print(f'\set {v.removeprefix(":")} {k}',end=' ')
print()
#for o in out:
print(' '.join(out))
