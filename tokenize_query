#!/usr/bin/python3

from enum import Enum
from itertools import product
import fileinput
from random import shuffle
import sys

class State(Enum):
    START = 1
    IN_STRING = 2
    OTHER = 3
    NUMERIC = 4
    WORD = 5
    COMMENT = 6
    SPACE = 7

def tokenize(input):
    """Turn the input string into a list of strings based on simple
    tokenization rules (basically quoted strings are a single
    token). there is implicit whitespace between all tokens.
"""
    state = State.START
    ret = ''
    qc = ''

    i = -1

    while i < len(input) - 1:
        i = i + 1
        c = input[i]
        nextc = input[i+1] if i < len(input) - 1 else None

        if state == State.IN_STRING:
            ret = ret + c
            if c == qc:
                if len(ret) > 0:
                    yield (ret,state)
                    ret = ''
                state = State.START
        elif state == State.COMMENT:
            # we are discarding comments, so just ignore anything that isn't our closing sequence
            if qc == "\n" and c == "\n":
                state = State.START
            elif c == "*" and input[i+1] == '/':
                state = State.START
                i = i + 1
        else:
            if c in "\"'":
                ctype = State.IN_STRING
                qc = c
            elif c == '-' and nextc == '-':
                ctype = State.COMMENT
                qc = '\n'
            elif c == '/' and nextc == '*':
                ctype = State.COMMENT
                qc = '/'
            elif c.isspace():
                ctype = State.SPACE
            elif (c.isdigit() and state == State.START) or (c == '.' and state == State.NUMERIC):
                ctype = State.NUMERIC
            elif c.isalnum() or c == '_':
                ctype = State.WORD
            else:
                ctype = State.OTHER

            if len(ret) > 0 and state != ctype:
                yield (ret,state)
                ret = ''
            ret = ret + c
            state = ctype
    if len(ret) > 0: yield (ret,state)

def idents():
    lists = []
    while True:
        chars = [chr(n) for n in range(ord('a'), ord('z') + 1)] + [chr(n) for n in range(ord('A'), ord('Z') + 1)]
        shuffle(chars)
        lists.append(chars)
        for c in product(*lists):
            yield ':' + (''.join(c))

ident = iter(idents())
xform = dict()

out = []
for line in fileinput.input():
    last_st = None
    replaced = False
    for t,st in tokenize(line):
        sys.stderr.write(f"{(t,st)}")
        if st not in [State.COMMENT, State.SPACE]:
            if (replaced and st in [State.WORD, State.NUMERIC]) or st == last_st:
                out.append(' ')
            if len(t) > 2 and t[0].isalpha() or t[0] in "-_":
                #print(f'transforming {t}')
                # we are a transformable token
                key = xform.setdefault(t.lower(), next(ident))
                out.append(key)
                replaced = True
            else:
                out.append(t)
                replaced = False
            last_st = st
for k,v in sorted(xform.items()):
    print(f'\set {v.removeprefix(":")} {k}',end=' ')
print()
#for o in out:
print(''.join(out))
